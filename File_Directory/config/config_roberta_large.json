{
  "global": {
    "app_name": "roberta_large_base",
    "use_parallel": false,
    "num_of_device": 1,
    "batch_size": 4,
    "max_seq_length": 512,
    "pretrained_model_type": "roberta_large",
    "load_model_path": "File_Directory/pretrained/roberta_large"
  },
  "dataset": {
    "vocab_name": "vocab_roberta",
    "shuffle": true
  },
  "build": {
    "hidden_size": 1024,
    "num_hidden_layers": 24,
    "num_attention_heads": 16,
    "hidden_act": "gelu",
    "vocab_size": 21128
  },
  "train": {
    "max_epoch": 2,
    "base_learning_rate": 3e-5,
    "learning_rate_strategy": "linear_warm_up_and_decay",
    "warm_up_step": 800,
    "decay_step": 8000,
    "start_learning_rate": 0,
    "end_learning_rate": 1e-8,
    "optimizer": "adam",
    "regularization": "L2",
    "regularization_coeff": 0.01,
    "read_checkpoint": false,
    "print_per_step": 100,
    "snapshot_frequency": 1000,
    "validate_frequency_step": 1000
  },
  "predict": {

  }
}
